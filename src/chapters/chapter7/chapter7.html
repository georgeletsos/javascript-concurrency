<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <link
      rel="stylesheet"
      href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
      integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO"
      crossorigin="anonymous"
    />

    <link rel="stylesheet" href="../../css/main.css" />

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/default.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>

    <script src="https://unpkg.com/tippy.js@3/dist/tippy.all.min.js"></script>

    <script src="https://parallel.js.org/js/parallel.js"></script>

    <title>Javascript Concurrency</title>
  </head>
  <body>
    <div class="row no-gutters">
      <div class="col-12 p-2 sidebar sidebar-mobile">
        <div class="d-flex justify-content-between">
          <h5 class="m-0">
            <a href="../../index.html">Javascript Concurrency</a>
          </h5>
          <div class="hamburger hamburger--spin">
            <div class="hamburger-box"><div class="hamburger-inner"></div></div>
          </div>
        </div>
      </div>
      <div
        class="col-12 col-sm-12 col-md-12 col-lg-3 col-xl-3 p-2 sidebar sidebar-main"
      >
        <h5><a href="../../index.html">Javascript Concurrency</a></h5>
        <ul class="nav flex-column table-of-contents">
          <li class="nav-item">
            <a class="nav-link" href="../chapter1/chapter1.html">
              Chapter 1: Why JavaScript Concurrency?
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../chapter2/chapter2.html">
              Chapter 2: The JavaScript Execution Model
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../chapter3/chapter3.html">
              Chapter 3: Synchronizing with Promises
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../chapter4/chapter4.html"
              >Chapter 4: Lazy Evaluation with Generators</a
            >
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../chapter5/chapter5.html"
              >Chapter 5: Working with Workers</a
            >
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../chapter6/chapter6.html">
              Chapter 6: Practical Parallelism</a
            >
          </li>
          <li class="nav-item">
            <a class="nav-link active"> Chapter 7: Abstracting Concurrency </a>
            <ul>
              <li>
                <a href="#writing-concurrent-code">Writing concurrent code</a>
              </li>
              <li>
                <a href="#hiding-the-concurrency-mechanism"
                  >Hiding the concurrency mechanism</a
                >
              </li>
              <li><a href="#without-concurrency">Without concurrency</a></li>
              <li>
                <a href="#worker-communication-with-promises"
                  >Worker communication with promises</a
                >
              </li>
              <li><a href="#helper-functions">Helper functions</a></li>
              <li>
                <a href="#extending-postMessage">Extending postMessage()</a>
              </li>
              <li>
                <a href="#synchronizing-worker-results"
                  >Synchronizing worker results</a
                >
              </li>
              <li><a href="#lazy-workers">Lazy workers</a></li>
              <li><a href="#reducing-overhead">Reducing overhead</a></li>
              <li>
                <a href="#generating-values-in-workers"
                  >Generating values in workers</a
                >
              </li>
              <li><a href="#lazy-worker-chains">Lazy worker chains</a></li>
              <li><a href="#using-parallel-js">Using Parallel.js</a></li>
              <li><a href="#how-it-works">How it works</a></li>
              <li><a href="#spawning-workers">Spawning workers</a></li>
              <li><a href="#mapping-and-reducing">Mapping and reducing</a></li>
              <li><a href="#worker-pools">Worker pools</a></li>
              <li><a href="#allocating-pools">Allocating pools</a></li>
              <li><a href="#scheduling-jobs">Scheduling jobs</a></li>
            </ul>
          </li>
        </ul>
      </div>
      <div
        class="col-12 col-sm-12 col-md-12 col-lg-9 offset-lg-3 col-xl-9 offset-xl-3 main-content"
      >
        <div class="container">
          <h4>Chapter 7: Abstracting Concurrency</h4>
          <p>
            Up until this point in the book, we explicitly modelled concurrency
            issues in our code. With promises, we synchronized two or more
            asynchronous actions. With generators, we created data on-the-fly,
            avoiding unnecessary memory allocations. Finally, we learned that
            web workers are the workhorses that leverage multiple CPU cores.
          </p>
          <p>
            In this chapter, we will take all these ideas and put them into the
            context of application code. That is, if concurrency is the default,
            then we will need to make concurrency as unobtrusive as possible.
            We'll start by exploring various techniques that will help us
            encapsulate concurrency mechanisms within the components that we
            use. Then, we will move straight to improving our code from the
            previous two chapters by using promises to facilitate worker
            communication.
          </p>
          <p>
            Once we're able to abstract worker communication using promises,
            we'll look at implementing lazy workers with the help of generators.
            We'll also cover worker abstraction using the
            <em>Parallel.js</em> library, followed by the concept of worker
            pools.
          </p>

          <div id="writing-concurrent-code">
            <h5>Writing concurrent code</h5>
            <p>
              Concurrent programming is hard to get right. Even with contrived
              example applications, the bulk of complexity comes from concurrent
              code. We obviously want our code to be readable while keeping the
              benefits of concurrency. We want to get the most out of each CPU
              on the system. We only want to compute what we need, when we need
              it. We don't want spaghetti code that joins together several
              asynchronous operations. Focusing on all these aspects of
              concurrent programming while developing applications detracts from
              what we should really be focusing on—the features that give our
              application value.
            </p>
            <p>
              In this section, we'll look at the approaches that we might use to
              insulate the rest of our application from tricky concurrency bits.
              This generally means making concurrency the default mode—even when
              there's no real concurrency happening under the hood. In the end,
              we don't want our code to contain 90% concurrency acrobatics and
              10% functionality.
            </p>
          </div>

          <div id="hiding-the-concurrency-mechanism">
            <h5>Hiding the concurrency mechanism</h5>
            <p>
              The difficulty with exposing concurrency mechanisms all throughout
              our code is that they're all slightly different from one another.
              This magnifies the callback hell that we may already find
              ourselves in. For example, not all concurrent operations are
              network requests that fetch data from some remote resource.
              Asynchronous data might come from a worker or some another
              callback that's asynchronous in itself. Picture a scenario where
              we have three disparate data sources used to compute a value that
              we need—all of which are asynchronous.
            </p>
            <p>
              That value is the thing we care about in our application code.
              From the perspective of the feature that we're building we don't
              care about anything below it. So, our front-end architecture needs
              to encapsulate the complexities associated with concurrency.
              There's another complication to consider here in addition to all
              our asynchronous data sources—what about when the data isn't
              asynchronous and originates from a local source? What about
              synchronizing a local data source and an HTTP request? We'll cover
              this in the following section.
            </p>
          </div>

          <div id="without-concurrency">
            <h5>Without concurrency</h5>
            <p>
              Just because we're writing a concurrent JavaScript application,
              not every operation is inherently concurrent. For example, if one
              component asks another component for data that it already has in
              memory, then it's not an asynchronous operation and is returned
              immediately. Our application is likely filled with operations like
              these, where concurrency simply doesn't make sense. And therein
              lies the challenge—how do we mix asynchronous operations
              seamlessly with synchronous operations?
            </p>
            <p>
              The simple answer is that we make the default assumption of
              concurrency everywhere. Promises make this problem tractable.
            </p>
            <p>
              The key aspect of promises is their general ability to abstract
              synchronization problems away for us. This is applicable not just
              with network requests, but also web worker messages, or any other
              asynchronous operation that relies on callbacks. It requires a bit
              of an adjustment to think about our data as we promise that it'll
              get here eventually. But, once we close this mental gap,
              concurrency is enabled by default. Concurrency is the default as
              far as our features are concerned, and what we do behind the
              operating curtain isn't disruptive in the slightest.
            </p>
            <p>
              Let's turn our attention to some code now. We'll create two
              functions: one asynchronous and the other a plain old function
              that simply returns a value. The goal here is to make the code
              that uses these functions the same, despite the major differences
              in how the value is generated:
            </p>
            <div class="snippet1">
              <pre><code class="code-block javascript"></code><button class="btn btn-secondary shadow-none run-code-button">Run</button></pre>
            </div>
            <p>
              The trade-off here is the added promise complexity, wrapped around
              what would otherwise be a simple value returned from a function.
              But in reality, the complexity is encapsulated within the promise,
              and if we weren't writing a concurrent application, we obviously
              would need to concern ourselves with issues such as these. The
              benefit is huge. When everything is a promised value, we can
              safely rule out the inconsistencies that lead to nasty concurrency
              bugs.
            </p>
          </div>

          <div id="worker-communication-with-promises">
            <h5>Worker communication with promises</h5>
            <p>
              We now have a handle on why treating primitive values as promises
              benefits our code. It's time to apply this concept to web workers.
              In the preceding two chapters, our code that synchronized
              responses coming from web workers started to look a little
              intractable. This was because we were essentially trying to
              emulate many boilerplate chores that promises are good at
              handling. We'll first attempt to solve these problems by creating
              helper functions that wrap the worker communications for us,
              returning promises. Then we'll try another approach that involves
              extending the web worker interface at a lower level. Lastly, we'll
              look at some more complex synchronization scenarios that involve
              multiple workers, such as those from the last chapter.
            </p>
          </div>

          <div id="helper-functions">
            <h5>Helper functions</h5>
            <p>
              It would be ideal if we could get web worker responses back in the
              form of a promise resolution. But, we need to create the promise
              in the first place—how do we do this? Well, we could manually
              create the promise, where the message that's sent to the worker is
              sent from within the promise
              <span class="term" data-term="executor">executor function</span>.
              But, if we take this approach, we're not much better off than we
              were before introducing promises.
            </p>
            <p>
              The trick is to encapsulate both the message posted to the worker
              and any message received from the worker, within a single helper
              function.
            </p>
            <p>
              Let's take a look at an example helper function that implements
              this pattern. First, we'll need a worker that carries out some
              task—we'll start with this:
            </p>
            <div class="snippet2">
              <!-- prettier-ignore -->
              <pre><code class="code-block javascript"></code></pre>
            </div>
            <p>
              Here we have a worker that will square any number we pass it. This
              <em>work()</em> function is intentionally slow so that we can see
              how our application, as a whole, performs when web workers take
              longer than usual to complete a task. It also uses an ID as we've
              seen with our previous web worker examples, so it can reconcile
              with the code that sent the message. Let's implement the helper
              function that uses this worker now:
            </p>
            <div class="snippet3">
              <pre><code class="code-block javascript"></code><button class="btn btn-secondary shadow-none run-code-button">Run</button></pre>
            </div>
            <p>
              If we focus on the way that the <em>square()</em> function is
              used, passing a number argument and getting a promise as a return
              value, we can see that this fits in with our earlier discussion on
              making code concurrent by default. For example, we can completely
              remove workers from this scenario and simply change the way the
              helper function resolves the promise that it returns, and the rest
              of our code will continue to function unaltered.
            </p>
            <p>
              The helper function tactic is just one approach to simplify worker
              communication using promises. Perhaps we can decide that we don't
              necessarily want to maintain a bunch of helper functions. Next,
              we'll look at a more granular approach than helper functions.
            </p>
          </div>

          <div id="extending-postMessage">
            <h5>Extending postMessage()</h5>
            <p>
              Rather than amassing vast quantities of helper functions, we can
              take a more generic route. There's nothing wrong with helper
              functions; they're direct and to the point. If we reach a point
              where there are literally hundreds of them, their value would
              start to depreciate very quickly. The more generic approach is to
              keep using <em>worker.postMessage()</em>.
            </p>
            <p>
              So let's see if we can make this method return a promise just like
              our helper function from the previous section. This way, we keep
              using the granular <em>postMessage()</em> method, but improve our
              synchronization semantics. First, here's the worker code:
            </p>
            <div class="snippet4">
              <!-- prettier-ignore -->
              <pre><code class="code-block javascript"></code></pre>
            </div>
            <p>
              This is nothing radically different from what we've seen so far in
              our web worker code. Now, in the main thread, we have to figure
              out how to alter the interface of <em>Worker</em>. Let's do this
              now. Then, we'll try posting some messages to this worker and
              resolving promises as a response:
            </p>
            <div class="snippet5">
              <pre><code class="code-block javascript"></code><button class="btn btn-secondary shadow-none run-code-button">Run</button></pre>
            </div>
            <p>
              Well, this is exactly what we need, right? We can post message
              data directly to the worker, and the response data is sent back to
              us through the promise resolution. As an added bonus, we can
              actually wrap helper functions around this new
              <em>postMessage()</em> function implementation if we're so
              inclined. The main trick involved with making this work is storing
              a reference to the original <em>postMessage()</em>. Then, we
              override the web worker property <em>postMessage</em>, not the function
              itself. Finally, we can reuse it to add the necessary
              reconciliation and promise goodness.
            </p>
          </div>

          <div id="synchronizing-worker-results">
            <h5>Synchronizing worker results</h5>
            <p>
              The code in the last two sections has adequately reduced our web
              worker callback hell to a more tolerable level. In fact, now that
              we've got a handle on how to encapsulate web worker communication
              by having <em>postMessage()</em> return a promise, we're ready to
              start simplifying any messy worker code that isn't using this
              approach. The examples that we've looked at so far, have
              benefited greatly from promises, they are simple; not having these
              abstractions wouldn't be the end of the world.
            </p>
            <p>
              What about the scenario where we map a collection of data and then
              reduce the mapped collection? We may recall the map reduce code
              got a little hairy in
              <a href="../chapter6/chapter6.html"
                >Chapter 6, Practical Parallelism</a
              >. This is mostly due to all the worker communication boilerplate
              code entangled with the code that's trying to execute a map/reduce
              operation. Let's see if we fair any better using our promise
              technique. First, we'll create a very basic worker:
            </p>
            <div class="snippet6">
              <!-- prettier-ignore -->
              <pre><code class="code-block javascript"></code></pre>
            </div>
            <p>
              We can use this worker to pass arrays for mapping. So we'll create
              two of them and split the workload between the two workers, shown
              as follows:
            </p>
            <div class="snippet7">
              <pre><code class="code-block javascript"></code><button class="btn btn-secondary shadow-none run-code-button">Run</button></pre>
            </div>
            <p>
              When this is all we need to post data to workers, and to
              synchronize data from two or more workers, we're actually
              motivated to write concurrent code—it looks the same as the rest
              of our application code now.
            </p>
          </div>

          <div id="lazy-workers">
            <h5>Lazy workers</h5>
            <p>
              It's time for us to look at web workers from a different angle.
              The fundamental reason we're using workers in the first place is
              that we want to compute more than we have in the past in the same
              amount of time. Doing this, as we now know, involves messaging
              intricacies, divide and conquer strategies so to speak. We have to
              get data into and out of the worker, usually as an array.
            </p>
            <p>
              Generators help us compute lazily. That is, we don't want to
              compute something or allocate data in memory until we really need
              it. Do web workers make this difficult or impossible to achieve?
              Or can we leverage generators to compute lazily and in parallel?
            </p>
            <p>
              In this section, we'll explore ideas related to using generators
              in web workers. First, we'll look at the overhead issues
              associated with web workers. Then, we'll write some code that uses
              generators to pass data in and out of workers. Finally, we'll see
              if we can lazily pass data through a chain of generators, all
              residing in web workers.
            </p>
          </div>

          <div id="reducing-overhead">
            <h5>Reducing overhead</h5>
            <p>
              The main thread can offload expensive operations web workers,
              running them in another thread. This means the DOM is able to
              paint pending updates and process pending user events. However, we
              still face the overhead of allocating large arrays and the time
              taken to update the UI. Despite parallel processing with web
              workers, our users could still face a slowdown because there's no
              update to the UI until the entire data set has been processed.
              Here is a visualization of the general pattern:
            </p>
            <p>
              This is a generic path taken by data with a single worker; the
              same approach applies when there are multiple workers. With this
              approach, we can't escape the fact that we need to serialize the
              data twice, and we have to allocate it twice. These overheads are
              merely to facilitate the worker communication and have very little
              to do with the application functionality that we're trying to
              implement.
            </p>
            <p>
              The overhead with arrays and serialization, required for worker
              communication, generally isn't a big deal. However, with larger
              collections, we could be faced with real performance issues,
              stemming from the very mechanism that we use to improve
              performance. So looking at worker communication from another
              perspective doesn't hurt, even if it's not necessary at first.
            </p>
            <p>
              Here's a variation of the generic path taken by most workers.
              Instead of allocating and serializing lots of data upfront,
              individual items are passed in and out of workers. This gives the
              UI a chance to update using the data that's been processed, before
              all of the processed data arrives.
            </p>
          </div>

          <div id="generating-values-in-workers">
            <h5>Generating values in workers</h5>
            <p>
              If we want to update the UI as our workers generate results, then
              they can't package the result set as an array to send back to the
              main thread after all the computations are done. While this
              happens, the UI sits there without responding to the user. We want
              a lazier approach where values are generated one at a time so that
              the UI can be updated sooner. Let's build an example that sends
              input to the web worker and sends results back at a much more
              granular level than what we've seen so far in this book. First,
              we'll create a worker; the code for it is as follows:
            </p>
            <div class="snippet8">
              <!-- prettier-ignore -->
              <pre><code class="code-block javascript"></code></pre>
            </div>
            <p>
              There's nothing earth-shattering here. It's the same
              <em>work()</em> function that we've already used to intentionally
              slow-down our code by inefficiently squaring a number. There's no
              actual generator used inside the worker. This is because we really
              don't need one, we'll see why in a moment:
            </p>
            <div class="snippet9">
              <pre><code class="code-block javascript"></code><button class="btn btn-secondary shadow-none run-code-button">Run</button></pre>
            </div>
            <p>
              Each number that's passed to our worker is more expensive to
              process than the previous number. So overall, processing the
              entire input array before showing anything to the user would feel
              as if the application is hanging or broken. But, this is not the
              case here because although each number is expensive to process,
              we're posting the results back as they become available.
            </p>
            <p>
              We perform the same amount of work as we would perform by passing
              in an array and getting back an array as output. However, this
              approach simply changes the order in which things happen. We've
              introduced cooperative multi-tasking into the picture—compute some
              data in one task and update the UI in another. The aggregate time
              taken to complete the work is the same, but to the user, it feels
              much faster. At the end of the day, the user perceivable
              performance of our application is the only performance metric that
              counts.
            </p>
            <p>
              <em
                >We passed in the input as individual messages. We could have
                passed in the input as an array, posted the results
                individually, and gotten the same effect. However, this would
                probably amount to nothing more than an unneeded complexity.
                There's a natural correspondence to the pattern as it is—item
                in, item out. Don't change it if you don't have to.</em
              >
            </p>
          </div>

          <div id="lazy-worker-chains">
            <h5>Lazy worker chains</h5>
            <p>
              As we saw in
              <a href="../chapter4/chapter4.html"
                >Chapter 4, Lazy Evaluation with Generators</a
              >
              we can assemble chains of generators. This is how we implement
              complex functionality lazily; an item flows through a chain of
              generator functions that transform the item before yielding to the
              next generator until it reaches the caller. Without generators, we
              would have to allocate a lot of intermediary data structures just
              for the sake of passing data from one function to the next.
            </p>
            <p>
              In the section prior to this one, we saw that a pattern similar to
              generators was possible with web workers. Since we face a similar
              problem here, we don't want to allocate large data structures. We
              can avoid doing this by passing in items at a more granular level.
              This has the added benefit of keeping the UI responsive because
              we're able to update it before the last item arrives from the
              worker. Given that we can do this much with workers, could we not
              build on this idea and assemble more complex chains of worker
              processing nodes?
            </p>
            <p>
              For instance, let's say we have a collection of numbers and
              several transformations. We need to make these transformations in
              a specific order before we can display them in our UI. Ideally, we
              would setup a chain of workers where each worker is responsible
              for performing its designated transformation, then passing the
              output on to the next worker. Eventually, the main thread gets a
              value back that it can display in the DOM.
            </p>
            <p>
              The problem with this goal is the tricky communication that it
              involves. Since dedicated workers only communicate with the main
              thread that created them, it's hardly advantageous to send the
              results back to the main thread, then onto the next worker in the
              chain, and so on. Well, it turns out that dedicated workers can
              directly communicate without involving the main thread. We can use
              something called channel messaging here. The idea is simple; it
              involves creating a channel, which has two ports—messages posted
              on one port and received on the other.
            </p>
            <p>
              We've been using messaging channels and ports all along. They're
              baked into web workers. This is where the message event and
              <em>postMessage()</em> method pattern comes from.
            </p>
            <p>
              The following is a visualization of how we would go about
              connecting our web workers using channels and ports:
            </p>
            <p>
              As we can see, each channel uses two messaging ports. The first
              port is used to post messages, whereas the second is used to
              receive message events. The only time the main thread is used is
              when the processing chain is first kicked off by posting a message
              to the first channel and when the message is received from the
              third channel.
            </p>
            <p>
              Instead of letting the six ports required for worker communication
              intimidate us, let's write some code; maybe, it'll look a little
              more approachable there. First we'll create the workers used in
              the chain. Actually, they're two instances of the same worker.
              Here's the code:
            </p>
            <div class="snippet10">
              <!-- prettier-ignore -->
              <pre><code class="code-block javascript"></code></pre>
            </div>
            <p>
              This is interesting. In this worker, we have message ports to work
              with. The first port is used to receive input, and the second port
              is used to send output. The <em>work()</em> function simply
              squares the given number using our now familiar approach of
              wasting CPU cycles to see how workers behave. What we want to do
              in our main thread is to create two instances of this worker so
              that we can pass the first instance a number to square. Then,
              without passing the result back to the main thread, it passes the
              result to the next worker, and the number is squared again. The
              communication paths should closely mimic the previous diagram.
              Let's look at some code that connects workers using messaging
              channels:
            </p>
            <div class="snippet11">
              <pre><code class="code-block javascript"></code><button class="btn btn-secondary shadow-none run-code-button">Run</button></pre>
            </div>
            <p>
              In addition to the data that we want to send to the worker, we can
              also send a list of message ports that we want to transfer to the
              worker context. This is what we do with the first two messages
              sent to the worker. The message data is <em>null</em> because
              we're not doing anything with it. In fact, these are the only
              messages we're sending directly to the worker. The rest of the
              communication happens through the message channels that we've
              created. The expensive computation happens on the worker because
              that's where the message handler resides.
            </p>
          </div>

          <div id="using-parallel-js">
            <h5>Using Parallel.js</h5>
            <p>
              The aim of the <em>Parallel.js</em> library is to make interacting
              with web workers as seamless as possible. In fact, it handles one
              of the key goals of this book—it hides the concurrency mechanism
              and allows us to focus on the application that we're building.
            </p>
            <p>
              In this section, we'll look at the approach taken by
              <em>Parallel.js</em> for worker communication and the general
              approach of passing code to workers. Then, we'll walk through some
              code that uses <em>Parallel.js</em> to spawn new worker processes.
              Lastly, we'll explore the built-in map/reduce capabilities that
              the library has to offer.
            </p>
          </div>

          <div id="how-it-works">
            <h5>How it works</h5>
            <p>
              All the workers that we've used so far in this book have been our
              own creation. We implemented message event handling in our workers
              that computed some value, then posted a response. With
              <em>Parallel.js</em>, we don't implement workers. Instead, we
              implement functions, which are then passed to workers that are
              managed by the library.
            </p>
            <p>
              This takes care of a few headaches for us. All our code is
              implemented in the main thread, meaning that it's easier to use
              the functions that we've implemented in the main thread because we
              don't need to import them into web workers using
              <em>importScripts()</em>. We also don't need to manually start web
              workers by creating them with a script path. Instead, we let
              <em>Parallel.js</em> spawn new workers for us, and then, we can
              tell the workers what to do by passing functions and data to them.
              So, how does this work, exactly?
            </p>
            <p>
              Workers need a script argument. Without a valid script, workers
              simply do not work. <em>Parallel.js</em> has a straightforward
              <em>eval</em> script. This is what's passed to any worker that the
              library creates. Then, the API within the main thread assembles
              code that's to be evaluated within the worker and sends it over
              whenever we need to communicate with workers.
            </p>
            <p>
              This is feasible because <em>Parallel.js</em> doesn't aim to
              expose a plethora of functionality backed by workers. Instead, the
              aim is to make the worker communication mechanism as seamless as
              possible while providing minimal functionality. This makes it easy
              to build only the concurrency functionality that's relevant to our
              application and not a host of other functions that we'll never
              use.
            </p>
            <p>
              Here is an illustration of how we pass data and code into a worker
              using <em>Parallel.js</em> and its <em>eval</em> script:
            </p>
          </div>

          <div id="spawning-workers">
            <h5>Spawning workers</h5>
            <p>
              The <em>Parallel.js</em> library has the notion of a job. The
              primary input to a job is the data that the job is going to
              process. The creation of a job isn't directly tied to the creation
              of a background worker. Workers are distinct from
              <em>Parallel.js</em> jobs; we don't interact directly with workers
              when using the library. Once we have our job instance, and it's
              supplied with our data, we use a job method to invoke workers.
            </p>
            <p>
              The most basic method is <em>spawn()</em>, which takes a function
              as an argument and runs it in a web worker. The function that we
              pass to it can return results, and these are then resolved as a
              thenable object that's returned by <em>spawn()</em>. Let's look at
              some code that uses <em>Parallel.js</em> to spawn new job backed
              by a web worker:
            </p>
            <div class="snippet12">
              <pre><code class="code-block javascript"></code><button class="btn btn-secondary shadow-none run-code-button">Run</button></pre>
            </div>
            <p>
              Well now, that's pretty cool; we don't have to worry about any of
              the monotonous web worker life-cycle tasks. We have some data and
              some function that we want to apply to the data, and we want to
              run it in parallel with other work taking place on the page. The
              cherry on the top is the familiar thenable that's returned from
              the <em>spawn()</em> method. It fits right into our concurrent
              application, where everything else is treated as a promise.
            </p>
            <p>
              We log how long it takes for our function to process the input
              data we give it. We only spawn a single web worker for this task,
              so the result is reached in the same amount of time as it would
              have been, were it computed in the main thread. Aside from freeing
              up the main thread to handle DOM events and repainting, there's no
              objective performance gain. We'll see if we can use a different
              method to up the concurrency level.
            </p>
            <p>
              <em
                >The worker created by <em>spawn()</em> is immediately
                terminated when we're done with it. This frees up memory for us.
                However, there's no concurrency level governing the use of
                <em>spawn()</em>, we can call it 100 times in a row if we
                like.</em
              >
            </p>
          </div>

          <div id="mapping-and-reducing">
            <h5>Mapping and reducing</h5>
            <p>
              In the last section, we spawned a worker thread using the
              <em>spawn()</em> method. <em>Parallel.js</em> also has a
              <em>map()</em> method and a <em>reduce()</em> method. The idea is
              to make things easier for us. By passing <em>map()</em> a
              function, the library will automatically apply it to each item in
              the job data. Similar semantics apply with the
              <em>reduce()</em> method. Let's take a look at how this works by
              writing some code:
            </p>
            <div class="snippet13">
              <pre><code class="code-block javascript"></code><button class="btn btn-secondary shadow-none run-code-button">Run</button></pre>
            </div>
            <p>
              Ouch! This is quite the performance hit—what's going on here? What
              we're seeing here is a phenomenon called parallel slowdown. This
              slowdown takes place when there's too much parallel communication
              overhead. The reason this is happening in this particular example
              is due to the way <em>Parallel.js</em> processes arrays in
              <em>map()</em>. Each array item goes through a worker. This
              doesn't mean that 'there are 2500 workers created—one for each
              element in the array. The number of created workers maxes out at
              four or the <em>navigator.hardwareConcurrency</em> value—similar
              semantics we looked at earlier in this book.
            </p>
            <p>
              The real overhead comes from messages sent to and received from
              the workers—5000 messages! This is obviously not optimal, as
              evidenced by the timer in the code. Let's see if we can make a
              drastic improvement on these numbers while keeping roughly the
              same code structure:
            </p>
            <div class="snippet14">
              <pre><code class="code-block javascript"></code><button class="btn btn-secondary shadow-none run-code-button">Run</button></pre>
            </div>
            <p>
              Here, we can see that the same results are generated, and much
              faster. The difference is that we start things off by slicing the
              array into chunks of smaller arrays. These arrays are the items
              that get passed to the workers, instead of individual numbers. So
              the mapping job has to change slightly as well, instead of
              squaring a number, it's mapping a smaller array to an array of
              squares. The reduce logic is slightly more complex, but overall,
              our approach is still the same. Most importantly, we've removed
              the heavy message-passing bottleneck that was causing unacceptable
              performance flaws in the first implementation.
            </p>
            <p>
              <em
                >Just like the <em>spawn()</em> method cleans up the worker when
                it returns, so too do the <em>map()</em> and <em>reduce()</em>
                <em>Parallel.js</em> methods. The downside to freeing workers is
                that they need to be recreated whenever these methods are
                called. We'll address this challenge in the next section.</em
              >
            </p>
          </div>

          <div id="worker-pools">
            <h5>Worker pools</h5>
            <p>
              The final section of this chapter covers the concept of worker
              pools. In the preceding section on <em>Parallel.js</em>, we ran up
              against an issue where workers were frequently created and
              terminated. This is a lot of overhead. If we know the level of
              concurrency we're capable of operating at, then why not allocate a
              statically-sized pool of workers that can take on work?
            </p>
            <p>
              The first design task for creating a worker pool is to allocate
              the workers. The next step is to schedule the jobs as they come in
              by distributing them to available workers in the pool. Lastly,
              we'll need to account for busy states when all the workers are
              busy. Let's do this.
            </p>
          </div>

          <div id="allocating-pools">
            <h5>Allocating pools</h5>
            <p>
              Before we think about allocating pools of worker threads, we need
              to look at the overarching worker pool abstraction. How do we want
              it to look and behave? Ideally, we want the pool abstraction to
              look and behave like a plain dedicated worker. We can post a
              message to the pool and get a promise in response. So while we
              can't directly extend the Worker prototype, we can create a new
              abstraction that closely resembles the Worker API.
            </p>
            <p>
              Let's look at some code now. Here's the initial abstraction that
              we'll use:
            </p>
            <div class="snippet15">
              <!-- prettier-ignore -->
              <pre><code class="code-block javascript"></code></pre>
            </div>
            <p>
              When a new <em>WorkerPool</em> is created, the given script is
              used to spawn all the workers within the pool. The
              <em>workers</em> property is a <em>Map</em> instance, and the
              worker instances themselves are the keys. The reason we store the
              workers as map keys is so that we can easily lookup the
              appropriate resolver function to call.
            </p>
            <p>
              When a given worker responds, the <em>message</em> event handler
              that we've added to each worker is called, and this is where we
              find the resolver function that's waiting to be called. There's no
              chance of us calling the wrong resolver because a given worker
              doesn't take on new work until it's finished with its current
              task.
            </p>
          </div>

          <div id="scheduling-jobs">
            <h5>Scheduling jobs</h5>
            <p>
              Now we'll implement the <em>postMessage()</em> method. This is
              what the caller will use to post a message to one of the workers
              in the pool. The caller doesn't know which worker fulfills their
              request, nor do they care. They get a promise as a return value,
              and it's resolved with the worker response as the value:
            </p>
            <div class="snippet16">
              <!-- prettier-ignore -->
              <pre><code class="code-block javascript"></code></pre>
            </div>
            <p>
              It's the promise executor function that takes care of actually
              finding the first available worker and posting our message there.
              When an available worker is found, we also set the worker's
              resolver function in our <em>workers</em> map. If there are no
              available <em>workers</em> in the pool, the posted message goes
              into the <em>queue</em>. This queue is emptied in the
              <em>message</em> event handler. This is because when a worker
              comes back with a message, it means the worker is free to take on
              more work, and it checks if there's anything queued before
              returning to an idle state.
            </p>
            <p>
              The <em>getWorker()</em> method is a simple helper that finds the
              next available worker for us. We know a worker is available to
              take on a task if its resolver function is set to null in the
              <em>workers</em> map. Lastly, let's see this worker pool in
              action:
            </p>
            <div class="snippet17">
              <pre><code class="code-block javascript"></code><div class="input-group position-absolute" style="width: 200px; top: 4px; right: 4px;">
                    <input type="text" class="form-control" placeholder="Amount" amount>
                    <div class="input-group-append">
                      <button class="btn btn-outline-secondary" type="button" work>Work</button>
                    </div>
                  </div></pre>
            </div>
            <p>
              In this usage scenario, we have a couple of form controls that
              send parameterized work to the worker. The larger the number, the
              longer the work will take; it uses our standard
              <em>work()</em> function that slowly squares numbers. If we use a
              large number and frequently click the button that posts the
              message to the pool, then eventually, we'll exhaust the pool. If
              'this is the case, we will display a warning. However, this is
              just for troubleshooting purposes—the posted messages aren't lost
              when the pool is busy, they're simply queued.
            </p>
          </div>
        </div>
      </div>
    </div>

    <script src="./snippets.js"></script>
    <script src="../../js/main.js"></script>
  </body>
</html>
